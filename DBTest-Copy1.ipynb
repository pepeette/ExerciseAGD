{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c3b0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import dash\n",
    "from dash import dash_table\n",
    "from dash.dash_table.Format import Group\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State, ClientsideFunction, MATCH, ALL, ClientsideFunction, Output, Input\n",
    "from dash.exceptions import PreventUpdate\n",
    "import dash_bootstrap_components as dbc\n",
    "#from navbar_tabs_layout import app_layout\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from flask_caching import Cache\n",
    "import webbrowser as web\n",
    "from threading import Timer\n",
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c55d7c-9066-4346-8b2d-e32ae6e266e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#web.open_new_tab('http://127.0.0.1:8090/')\n",
    "def open_browser():\n",
    "    web.open_new(\"http://localhost:{}\".format(8080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b561aef-fda1-40c0-9520-4dca18cf8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CERULEAN], meta_tags=[{\"name\": \"viewport\", \"content\": \"width=device-width\"}])\n",
    "app.title = 'Dashboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f029bd-b644-4034-815f-1aaf293129cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flask caching\n",
    "cache = Cache(app.server, config={\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': 'cache-directory',\n",
    "    'CACHE_DEFAULT_TIMEOUT': 86400  # 24 hours\n",
    "})\n",
    "store = dcc.Store(id='local', storage_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b759473-ce84-41d1-924d-a283786e1afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd23de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.astype({'application_id': str,'candidate_id': str,'stage_name': str,'status': str})\n",
    "    convert = ['source_id', 'job_id', 'referrer_id', 'rejection_reason_type_id', 'rejection_reason_id']\n",
    "    df[convert] = df[convert].apply(pd.to_numeric, errors='coerce')\n",
    "    df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "    df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "    #only select clean data\n",
    "    df = df[df['stage_name']!= 'Interview 1 - F2F - delete']\n",
    "    df = df[df['isDelete']==0]\n",
    "    #wait time until application ackowledged\n",
    "    df['entry_log_wait'] = (df['entered_on'] - df['applied_at']).dt.days\n",
    "    #length per application_id and refined per status\n",
    "    df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "    df['length_per_application'] = (df.groupby('application_id')['exited_on'].transform('last') - df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "    #total number of unique stage_name per application_id per candidate_id\n",
    "    df['unique_stages_per_application_candidate'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].transform('nunique')\n",
    "    #sum of different application_id per candidate_id\n",
    "    df['sum_applications_per_candidate'] = df.groupby('candidate_id')['application_id'].transform('nunique')\n",
    "    df['month'] = df['applied_at'].dt.month\n",
    "    df['year'] = df['applied_at'].dt.year\n",
    "    df['exit_flag'] = ''\n",
    "    for _, group in df.groupby(['candidate_id', 'application_id']):\n",
    "        sorted_group = group.sort_values('exited_on')\n",
    "        last_row_index = sorted_group.index[-1]\n",
    "        df.at[last_row_index, 'exit_flag'] = 'exit'\n",
    "    #clean stage_name\n",
    "    df['stage_name'] = df['stage_name'].replace({\n",
    "        'Recruiter aplication': 'Recruiter application',\n",
    "        'Recruiter applicaton': 'Recruiter application',\n",
    "        'Recruiter applicaton': 'Recruiter application'\n",
    "    })\n",
    "    df['stage_name'] = df['stage_name'].replace({'Interview 1 - Phone/Video': 'Interview 1',\n",
    "                                                'Interview 1 - F2F':'Interview 1',\n",
    "                                                'Interview 2 - Phone/Video':'Interview 2',\n",
    "                                                'Interview 2 - F2F':'Interview 2',\n",
    "                                                'Interview 3 - F2F':'Interview 3',\n",
    "                                                'Interview 3 - Phone/Video':'Interview 3',\n",
    "                                                })\n",
    "    # df['stage_name'] = df['stage_name'].replace({'Test:Take Home':'Test:SHL' })\n",
    "    df['stage_name'] = df['stage_name'].replace({'Application Review':'Hiring Manager application'})\n",
    "    #df['stage_name'] = df['stage_name'].replace({'Hiring Manager Review':'Recruiter Screening', 'Hiring Manager application':'Recruiter application'})\n",
    "    df = df.sort_values(['application_id','candidate_id','applied_at','entered_on', 'exited_on'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcde439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_current():\n",
    "    df1 = pd.read_excel(open('Case_Recruitment_Dataset.xlsx','rb'), 'dataset 1')\n",
    "    df2 = pd.read_excel(open('Case_Recruitment_Dataset.xlsx','rb'), 'dataset 2')\n",
    "    df = pd.merge(df1, df2, on=\"application_id\")\n",
    "    df = df[['candidate_id', 'application_id','stage_name','entered_on','exited_on',\n",
    "        'status','rejection_reason_type_id','rejection_reason_id','job_id','applied_at', \n",
    "         'source_id', 'referrer_id', 'isDelete']]\n",
    "    df = df.sort_values(['application_id','candidate_id','applied_at','entered_on','exited_on'])\n",
    "    # clean_data = preprocess_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a9e7f0-63d3-498f-87bf-8f10b5572743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned():\n",
    "    df = load_current()\n",
    "    clean_data = preprocess_data(df)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1bf42b-8072-4794-84d2-d35e921b73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('local', 'data'),\n",
    "              Output(\"loading-fetch-data\", \"children\"),\n",
    "              Input('fetch-data-button', 'n_clicks'))\n",
    "def fetch_data(n_clicks):\n",
    "    if n_clicks is None or n_clicks == 0:\n",
    "        stored_data = cache.get('data')\n",
    "        if stored_data is not None:\n",
    "            #data from cache if there\n",
    "            return stored_data, ''\n",
    "        else:\n",
    "            #else most recent data\n",
    "            clean_data = load_current()\n",
    "            cache.set('data', clean_data.to_json(date_format='iso', orient='split'))\n",
    "            if clean_data.empty:\n",
    "                return '', html.Div([\n",
    "                    html.P('Dataset not found.')\n",
    "                ])\n",
    "            else:\n",
    "                return clean_data.to_json(date_format='iso', orient='split'), ''  # clean_data.to_dict('records')\n",
    "    else:\n",
    "        try:\n",
    "            clean_df = load_cleaned()\n",
    "            cache.set('data', clean_df.to_json(date_format='iso', orient='split'))\n",
    "            return clean_df.to_json(date_format='iso', orient='split'), html.Div([\n",
    "                html.P('Data cleaned successfully')\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            return '', html.Div([\n",
    "                html.P('Preprocessing not completed', style={'color': 'red'})\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4a6628-77f9-420e-b495-c300954eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('table-container', 'children'),\n",
    "              [Input('fetch-data-button', 'n_clicks'),\n",
    "               State('local', 'data')])\n",
    "def update_data(n_clicks, data):\n",
    "    if n_clicks is None or n_clicks == 0:\n",
    "        json_resp = fetch_data(0)[0]\n",
    "    else:\n",
    "        json_resp = fetch_data(1)[0]\n",
    "    #convert json data to df\n",
    "    df = pd.read_json(json_resp, orient='split')\n",
    "    #show last row of df\n",
    "    last_row = df.tail(1)\n",
    "    #return table on dash\n",
    "    return None\n",
    "    return dbc.Container([\n",
    "        html.H6('Last row of dataset'),\n",
    "        dash_table.DataTable(\n",
    "            id='table',\n",
    "            columns=[{\"name\": i, \"id\": i} for i in last_row.columns],\n",
    "            data=last_row.to_dict('records'),\n",
    "            style_cell={'textAlign': 'center'},\n",
    "            style_header={\n",
    "                'backgroundColor': 'rgb(230, 230, 230)',\n",
    "                'fontWeight': 'bold'\n",
    "            },\n",
    "            style_data_conditional=[\n",
    "                {\n",
    "                    'if': {'row_index': 'odd'},\n",
    "                    'backgroundColor': 'rgb(248, 248, 248)'\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83bf82b-bf0a-4a3a-a90d-e53e0f35f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_data():\n",
    "    cached_data = cache.get('data')\n",
    "    if cached_data is not None:\n",
    "        df = pd.read_json(cached_data, orient='split')\n",
    "    else: \n",
    "        df = load_current()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6118cb-f20f-477e-bd35-0cb9dabb72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result layout \n",
    "search_container = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Input(id=\"input\", type=\"text\", placeholder=\"Ex: what is the average length of each unique stage_name based on exited_on and entered_on, ordered by length\", n_submit=1, style={'width': '100%'}), width=9),\n",
    "        dbc.Col(dbc.Button('Search', id='search-button', className='btn-primary'), width=2),\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='output-graph'), width=12, id='output-graph-container', style={'display': 'none'})\n",
    "    ])\n",
    "], fluid=True, style={'padding': '2rem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b6a9e5-24e8-4987-b75d-c590357460d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"output-graph-container\", \"style\"),\n",
    "    Output(\"output-graph\", \"figure\"),\n",
    "    Input(\"search-button\", \"n_clicks\"),\n",
    "    State(\"input\", \"value\")\n",
    ")\n",
    "def search_output(n_clicks, input_value):\n",
    "    if n_clicks is None:\n",
    "        raise PreventUpdate\n",
    "\n",
    "    df = load_cached_data()\n",
    "    llm = OpenAI(api_token=\"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\")\n",
    "    pandas_ai = PandasAI(llm)\n",
    "    prompt = input_value\n",
    "    result = pandas_ai.run(df, prompt=prompt)\n",
    "\n",
    "    # figure \n",
    "    if isinstance(result, go.Figure):\n",
    "        # Graph is returned\n",
    "        return {'display': 'block'}, result\n",
    "    else:\n",
    "        # Text is returned\n",
    "        return {'display': 'block'}, html.Div(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae94a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b36eb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "navbar = dbc.Navbar(\n",
    "    dbc.Container(\n",
    "        [\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(html.Img(src=\"images.jpg\", height=\"20px\"), width=\"auto\", align=\"center\"),\n",
    "                    dbc.Col(dbc.NavbarBrand(\"Recruitment Use Case\", className=\"ml-2\"), width=\"auto\", align=\"center\"),\n",
    "                    dbc.Col(html.Div(id=\"date\", children=date), width=\"auto\", align=\"center\"),\n",
    "                    dbc.Col(\n",
    "                        [\n",
    "                            dbc.Button('Add Pipeline Scenario', id='fetch-data-button', n_clicks=0, className=\"mr-2\"),\n",
    "                     dcc.Loading(\n",
    "                                id=\"loading-fetch-data\",\n",
    "                                type=\"default\",\n",
    "                                children=[\n",
    "                                    dbc.Button(id='query-status-button', children='',style={'width': 'auto', 'margin-left': '10px'})\n",
    "                                ]\n",
    "                            ),\n",
    "                            html.Div(id='status'),\n",
    "                        ],\n",
    "                        width=\"auto\", align=\"end\",style={'display': 'flex', 'align-items': 'center'}\n",
    "                    ),\n",
    "                    #html.Button(id='page-load', n_clicks=0, style={'display': 'none'}),\n",
    "                    html.Div(id='page-load', style={'display': 'none'}, children='page-load'),\n",
    "                ],\n",
    "                className=\"my-row\",\n",
    "                align=\"center\",\n",
    "            ),\n",
    "            dbc.NavbarToggler(id=\"navbar-toggler\"),\n",
    "        ]\n",
    "    ),\n",
    "    color=\"light\",\n",
    "    dark=False,\n",
    "    sticky=\"top\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c78703-a3b2-403f-88ca-84e848c713b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Department Statistics\"),\n",
    "                dbc.CardBody([\n",
    "                    html.P(\n",
    "                        \"OBJECTIVES : \"\n",
    "                        \"✔️ REDUCE FAILED HIRE RATE \"\n",
    "                        \"✔️ REDUCE COST PER HIRE \"\n",
    "                        \"✔️ IMPROVE CANDIDATE EXPERIENCE \"\n",
    "                        \"✔️ IMPROVE TALENT POOL\",\n",
    "                        style={\"font-size\": \"16px\", \"margin-top\": \"15px\"}\n",
    "                    ),\n",
    "                    dcc.Graph(id='high-level-table', config={'displayModeBar': False})\n",
    "                ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    # dbc.Row([\n",
    "    #     dbc.Col(\n",
    "    #         dbc.Card([\n",
    "    #             dbc.CardHeader(\"Influential Stage Analysis\"),\n",
    "    #             dbc.CardBody([\n",
    "    #                 dcc.Graph(id='correlation-heatmap')\n",
    "    #             ])\n",
    "    #         ], className=\"rounded-0 border-0\")\n",
    "    #     )\n",
    "    # ]),\n",
    "], fluid=True, style={'padding': '2rem 2rem 8rem 2rem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b030a9f-07d6-4424-9f93-70c52b5526f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_high_level_table():\n",
    "    df = load_cached_data()\n",
    "    #length per application_id and refined per status\n",
    "    df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "    df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "    \n",
    "    df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "    df['length_per_application'] = (df.groupby('application_id')['exited_on'].transform('last') - df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "\n",
    "    df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "    df['length_per_application'] = (df.groupby('application_id')['exited_on'].transform('last') - df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "    #total number of unique stage_name per application_id per candidate_id\n",
    "    df['unique_stages_per_application_candidate'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].transform('nunique')\n",
    "    #sum of different application_id per candidate_id\n",
    "    df['sum_applications_per_candidate'] = df.groupby('candidate_id')['application_id'].transform('nunique')\n",
    "    df['month'] = df['applied_at'].dt.month\n",
    "    df['year'] = df['applied_at'].dt.year\n",
    "    df['exit_flag'] = ''\n",
    "    for _, group in df.groupby(['candidate_id', 'application_id']):\n",
    "        sorted_group = group.sort_values('exited_on')\n",
    "        last_row_index = sorted_group.index[-1]\n",
    "        df.at[last_row_index, 'exit_flag'] = 'exit'\n",
    "    # High Level calculations\n",
    "    high_level = df.groupby('status').agg({\n",
    "        'candidate_id': 'nunique',\n",
    "        'application_id': 'nunique',\n",
    "        'sum_applications_per_candidate': 'median',\n",
    "        'unique_stages_per_application_candidate': 'median',\n",
    "        'length_per_application': 'mean',\n",
    "        #'stage_name': lambda x: x.mode()[0]\n",
    "        #'prev_stage_clean': lambda x: x.mode()[0]\n",
    "    })\n",
    "    high_level.columns = ['candidates', 'applications', 'applications per candidate (mid)', \n",
    "                          'stages per application (mid)', 'application length in days (avg)']#, 'most common previous stage']\n",
    "    high_level = high_level.sort_values('candidates', ascending = False)\n",
    "    high_level['application length in days (avg)'] = high_level['application length in days (avg)'].round(0)\n",
    "    \n",
    "    #percentage\n",
    "    high_level['% candidates'] = high_level['candidates'] / high_level['candidates'].sum() * 100\n",
    "    high_level['% applications'] = high_level['applications'] / high_level['applications'].sum() * 100\n",
    "    \n",
    "    high_level['% candidates'] = high_level['% candidates'].round(2)\n",
    "    high_level['% applications'] = high_level['% applications'].round(2)\n",
    "    high_level = high_level.sort_values('candidates', ascending=False)\n",
    "    \n",
    "    grand_total_values = {\n",
    "        'candidates': df['candidate_id'].nunique(),\n",
    "        '% candidates':'',\n",
    "        'applications': df['application_id'].nunique(),\n",
    "        '% applications':'',\n",
    "        'applications per candidate (mid)': df['sum_applications_per_candidate'].max(),\n",
    "        'stages per application (mid)': df['unique_stages_per_application_candidate'].max(),\n",
    "        'application length in days (avg)': df['length_per_application'].max(),\n",
    "        #'most common previous stage': ''\n",
    "    }\n",
    "    grand_total_row = pd.DataFrame(grand_total_values, index=['Total or Max (if avg)'])\n",
    "    \n",
    "    high_level = pd.concat([high_level, grand_total_row])\n",
    "    high_level = high_level[['candidates', '% candidates','applications','% applications', 'applications per candidate (mid)', \n",
    "                          'stages per application (mid)', 'application length in days (avg)']]#, 'most common previous stage']]\n",
    "        \n",
    "    # Define the formatting rules\n",
    "    formatting_rules = [\n",
    "        # ('% applications',lambda value:value<10),\n",
    "        ('applications per candidate (mid)', lambda value: value > 4),\n",
    "        ('stages per application (mid)', lambda value: value > 6),\n",
    "        ('application length in days (avg)', lambda value: value > 30)\n",
    "    ]\n",
    "    \n",
    "    # Create a list to store text colors\n",
    "    text_color = []\n",
    "    \n",
    "    # Apply conditional formatting and update text colors\n",
    "    for column_name, condition in formatting_rules:\n",
    "        column_colors = []\n",
    "        for value in high_level[column_name]:\n",
    "            if condition(value):\n",
    "                column_colors.append('red')\n",
    "            else:\n",
    "                column_colors.append('black')\n",
    "        text_color.append(column_colors)\n",
    "    \n",
    "    # Create the Plotly table trace\n",
    "    table_trace = go.Table(\n",
    "        header=dict(values=['status'] + list(high_level.columns)),\n",
    "        cells=dict(\n",
    "            values=[high_level.index] + [high_level[col] for col in high_level.columns],\n",
    "            line_color='darkslategray',\n",
    "            align='left',\n",
    "            font=dict(color=text_color),#, family=\"Lato\", size=20),\n",
    "            height=30\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create a Plotly figure with the table\n",
    "    figure = go.Figure(data=[table_trace])\n",
    "    figure.update_layout(\n",
    "        autosize=False,\n",
    "        height=500,\n",
    "        width=1200\n",
    "    )\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7707a5d5-073c-4ea2-9c08-c16b8ed5b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_high_level_table():\n",
    "#     df = load_cached_data()\n",
    "#     #length per application_id and refined per status\n",
    "#     df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "#     df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "    \n",
    "#     df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "#     df['length_per_application'] = (df.groupby('application_id')['exited_on'].transform('last') - df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "\n",
    "#     df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "#     df['length_per_application'] = (df.groupby('application_id')['exited_on'].transform('last') - df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "#     #total number of unique stage_name per application_id per candidate_id\n",
    "#     df['unique_stages_per_application_candidate'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].transform('nunique')\n",
    "#     #sum of different application_id per candidate_id\n",
    "#     df['sum_applications_per_candidate'] = df.groupby('candidate_id')['application_id'].transform('nunique')\n",
    "#     df['month'] = df['applied_at'].dt.month\n",
    "#     df['year'] = df['applied_at'].dt.year\n",
    "#     df['exit_flag'] = ''\n",
    "#     for _, group in df.groupby(['candidate_id', 'application_id']):\n",
    "#         sorted_group = group.sort_values('exited_on')\n",
    "#         last_row_index = sorted_group.index[-1]\n",
    "#         df.at[last_row_index, 'exit_flag'] = 'exit'\n",
    "#     # High Level calculations\n",
    "#     high_level = df.groupby('status').agg({\n",
    "#         'candidate_id': 'nunique',\n",
    "#         'application_id': 'nunique',\n",
    "#         'sum_applications_per_candidate': 'median',\n",
    "#         'unique_stages_per_application_candidate': 'median',\n",
    "#         'length_per_application': 'mean',\n",
    "#         #'stage_name': lambda x: x.mode()[0]\n",
    "#         #'prev_stage_clean': lambda x: x.mode()[0]\n",
    "#     })\n",
    "#     high_level.columns = ['candidates', 'applications', 'applications per candidate (mid)', \n",
    "#                           'stages per application (mid)', 'application length in days (avg)']#, 'most common previous stage']\n",
    "#     high_level = high_level.sort_values('candidates', ascending = False)\n",
    "#     high_level['application length in days (avg)'] = high_level['application length in days (avg)'].round(0)\n",
    "    \n",
    "#     #percentage\n",
    "#     high_level['% candidates'] = high_level['candidates'] / high_level['candidates'].sum() * 100\n",
    "#     high_level['% applications'] = high_level['applications'] / high_level['applications'].sum() * 100\n",
    "    \n",
    "#     high_level['% candidates'] = high_level['% candidates'].round(2)\n",
    "#     high_level['% applications'] = high_level['% applications'].round(2)\n",
    "#     high_level = high_level.sort_values('candidates', ascending=False)\n",
    "    \n",
    "#     grand_total_values = {\n",
    "#         'candidates': df['candidate_id'].nunique(),\n",
    "#         '% candidates':'',\n",
    "#         'applications': df['application_id'].nunique(),\n",
    "#         '% applications':'',\n",
    "#         'applications per candidate (mid)': df['sum_applications_per_candidate'].max(),\n",
    "#         'stages per application (mid)': df['unique_stages_per_application_candidate'].max(),\n",
    "#         'application length in days (avg)': df['length_per_application'].max(),\n",
    "#         #'most common previous stage': ''\n",
    "#     }\n",
    "#     grand_total_row = pd.DataFrame(grand_total_values, index=['Total or Max (if avg)'])\n",
    "    \n",
    "#     high_level = pd.concat([high_level, grand_total_row])\n",
    "#     high_level = high_level[['candidates', '% candidates','applications','% applications', 'applications per candidate (mid)', \n",
    "#                           'stages per application (mid)', 'application length in days (avg)']]#, 'most common previous stage']]\n",
    "\n",
    "    \n",
    "#     table_trace = go.Table(\n",
    "#         header=dict(values=['status'] + list(high_level.columns)),\n",
    "#         cells=dict(values=[high_level.index] + [high_level[col] for col in high_level.columns], height=30)\n",
    "#     )\n",
    "    \n",
    "#     figure = go.Figure(data=[table_trace])\n",
    "    \n",
    "#     figure.update_layout(\n",
    "#         autosize=False,\n",
    "#         height=500,\n",
    "#         width=1200\n",
    "#     )\n",
    "    \n",
    "#     return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6bd5f-5c75-4a60-9621-641d12c086f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f211bd-8140-45d1-a791-fd2314034862",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('high-level-table', 'figure'),\n",
    "    Input('high-level-table', 'clickData')  # Use any input if needed\n",
    ")\n",
    "def update_high_level_table(click_data):\n",
    "    # You can add more logic here if you want to update the table based on interactions\n",
    "    # For now, just return the generated table\n",
    "    return generate_high_level_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d98be27-b989-459f-b8b6-38c2fcf22e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = load_cached_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b944f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Recruitment Stages Graph\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='sankey-graph')\n",
    "                ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Stage analysis\"),\n",
    "                dbc.CardBody([\n",
    "                    dbc.Row([\n",
    "                        dbc.Col(\n",
    "                            dcc.Dropdown(\n",
    "                                id='stage-dropdown',\n",
    "                                options=[],\n",
    "                                placeholder=\"Select a stage\",\n",
    "                                style={'width': '100%'}\n",
    "                            ),\n",
    "                            width=6\n",
    "                        ),\n",
    "                    ], className=\"mb-3\"),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col(\n",
    "                            html.Div(id='stage-duration-output')\n",
    "                        )\n",
    "                    ]),\n",
    "                    dbc.Row([\n",
    "                        dbc.Col(\n",
    "                            html.Div(id='backward-table-output')\n",
    "                        ),\n",
    "                        dbc.Col(\n",
    "                            html.Div(id='forward-table-output')\n",
    "                        )\n",
    "                    ])\n",
    "                ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dcc.Graph(id='duration-graph'),\n",
    "                dcc.RadioItems(\n",
    "                    id='data-selector',\n",
    "                    options=[\n",
    "                        {'label': 'All Applications', 'value': 'all'},\n",
    "                        {'label': 'Only Hired Applications', 'value': 'selected'},\n",
    "                    ],\n",
    "                    value='all',\n",
    "                )\n",
    "            ],className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Stages with High Durations until 'Hired'\"),\n",
    "                dbc.CardBody(\n",
    "                    [\n",
    "                        html.Div(id='high-duration-stages'),\n",
    "                        dcc.Graph(id='distribution')\n",
    "                    ]\n",
    "                ),\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Influential Stage Analysis\"),\n",
    "                dbc.CardBody([\n",
    "                    dcc.Graph(id='correlation-heatmap')\n",
    "                ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "], fluid=True, style={'padding': '2rem 2rem 8rem 2rem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9400f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('sankey-graph', 'figure'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def update_sankey_graph(n_clicks):\n",
    "    df = load_cached_data()\n",
    "    df['next_stage_clean'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].shift(-1)\n",
    "    df['prev_stage_clean'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].shift(1)\n",
    "    path2 = df.dropna(subset=['next_stage_clean'])\n",
    "    source_target_pair2 = path2[['stage_name', 'next_stage_clean']].drop_duplicates()\n",
    "    source_target_pair2['source'] = source_target_pair2['stage_name'].astype('category').cat.codes\n",
    "    source_target_pair2['target'] = source_target_pair2['next_stage_clean'].astype('category').cat.codes\n",
    "    pairs2 = source_target_pair2.groupby(['source', 'target']).size().reset_index(name='count')\n",
    "    sankey_pairs2 = pairs2[['source', 'target', 'count']]\n",
    "    unique_stages2 = df['stage_name'].unique()\n",
    "    stage_mapping2 = {index: stage_name for index, stage_name in enumerate(unique_stages2)}\n",
    "    sankey_pairs2['source_stage'] = sankey_pairs2['source'].map(stage_mapping2)\n",
    "    sankey_pairs2['target_stage'] = sankey_pairs2['target'].map(stage_mapping2)\n",
    "    #sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            label=unique_stages2, \n",
    "        ),\n",
    "        link=dict(\n",
    "            source=sankey_pairs2['source'],\n",
    "            target=sankey_pairs2['target'],\n",
    "            value=sankey_pairs2['count'],\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    fig.update_layout(\n",
    "        #title='Sequences per application',\n",
    "        font=dict(size=12),\n",
    "        height=600,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce6679f-e3fa-4703-b9e4-5000322281e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(stage_name):\n",
    "    df = load_cached_data()\n",
    "    stage_names = df['stage_name'].unique()\n",
    "    stage_names = sorted(stage_names.tolist())\n",
    "    options = [{'label': stage, 'value': stage} for stage in stage_names]\n",
    "\n",
    "    if stage_name is None:\n",
    "        stage = stage_names[0]\n",
    "    else:\n",
    "        stage = stage_name\n",
    "    #generate stage analysis\n",
    "    df['next_stage_clean'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].shift(-1)\n",
    "    df['prev_stage_clean'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].shift(1)\n",
    "    path2 = df.dropna(subset=['next_stage_clean'])\n",
    "    source_target_pair2 = path2[['stage_name', 'next_stage_clean']].drop_duplicates()\n",
    "    source_target_pair2['source'] = source_target_pair2['stage_name'].astype('category').cat.codes\n",
    "    source_target_pair2['target'] = source_target_pair2['next_stage_clean'].astype('category').cat.codes\n",
    "    pairs2 = source_target_pair2.groupby(['source', 'target']).size().reset_index(name='count')\n",
    "    sankey_pairs2 = pairs2[['source', 'target', 'count']]\n",
    "    unique_stages2 = df['stage_name'].unique()\n",
    "    stage_mapping2 = {index: stage_name for index, stage_name in enumerate(unique_stages2)}\n",
    "    exit_stages = df['next_stage_clean'].dropna().unique()\n",
    "    sankey_pairs2['source_stage'] = sankey_pairs2['source'].map(stage_mapping2)\n",
    "    sankey_pairs2['target_stage'] = sankey_pairs2['target'].map(stage_mapping2)\n",
    "    analysis = df[df['stage_name'].str.contains(stage)]\n",
    "    backward = analysis['prev_stage_clean'].value_counts(normalize=True).sort_values(ascending=False)\n",
    "    forward = analysis['next_stage_clean'].value_counts(normalize=True).sort_values(ascending=False)\n",
    "\n",
    "    # Convert 'exited_on' and 'entered_on' columns to datetime\n",
    "    analysis['exited_on'] = pd.to_datetime(analysis['exited_on'])\n",
    "    analysis['entered_on'] = pd.to_datetime(analysis['entered_on'])\n",
    "    \n",
    "    # Calculate average duration per stage\n",
    "    analysis['duration'] = (analysis['exited_on'] - analysis['entered_on']).dt.days\n",
    "    avg_duration = analysis.groupby('stage_name')['duration'].mean()\n",
    "\n",
    "    #stage duration information\n",
    "    duration_info = html.Div([\n",
    "        # html.H4(\"Stage Duration\"),\n",
    "        html.P(f\"Average Duration: {avg_duration.mean():.2f} days\"),\n",
    "        #html.P(f\"Percentage of hired : {percentage}%\"),\n",
    "        # html.Ul([\n",
    "            # html.Li(f\"{exit_stage}: {avg_remaining_duration:.2f} days\" if not pd.isna(avg_remaining_duration) else f\"{exit_stage}: N/A\")\n",
    "            # for exit_stage, avg_remaining_duration in avg_remaining_durations.items()\n",
    "        # ])\n",
    "    ])\n",
    "\n",
    "    # Calculate average remaining duration until exit stage, split by status\n",
    "    avg_remaining_durations = {}\n",
    "    for exit_stage in exit_stages:\n",
    "        exit_stage_filter = analysis['next_stage_clean'] == exit_stage\n",
    "        remaining_duration = analysis[exit_stage_filter]['exited_on'] - analysis[exit_stage_filter]['entered_on']\n",
    "        avg_remaining_duration = remaining_duration.mean()\n",
    "        avg_remaining_durations[exit_stage] = avg_remaining_duration\n",
    "\n",
    "    #backward table\n",
    "    backward_table = html.Table(\n",
    "        [\n",
    "            html.Thead(html.Tr([html.Th('Previous Stage'), html.Th('Count')])),\n",
    "            html.Tbody([\n",
    "                html.Tr([html.Td(prev_stage), html.Td(f\"{count:.2%}\")]) for prev_stage, count in backward.items()\n",
    "            ])\n",
    "        ],\n",
    "        className='table'\n",
    "    )\n",
    "\n",
    "    #forward table\n",
    "    forward_table = html.Table(\n",
    "        [\n",
    "            html.Thead(html.Tr([html.Th('Next Stage'), html.Th('Count'), html.Th('Avg Remaining Duration')])),\n",
    "            html.Tbody([\n",
    "                html.Tr([html.Td(next_stage), html.Td(f\"{forward[next_stage]:.2%}\"), html.Td(f\"{avg_remaining_durations[next_stage].days:.2f} days\")]) for next_stage in forward.index\n",
    "            ])\n",
    "        ],\n",
    "        className='table'\n",
    "    )\n",
    "    \n",
    "    return options, stage if stage_name is None else stage_name, duration_info, backward_table, forward_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2137e06b-d5fa-4f0f-a3d7-f1321d811b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update values\n",
    "@app.callback(\n",
    "    Output('stage-dropdown', 'options'),\n",
    "    Output('stage-dropdown', 'value'),\n",
    "    Output('stage-duration-output', 'children'),\n",
    "    Output('backward-table-output', 'children'),\n",
    "    Output('forward-table-output', 'children'),\n",
    "    Input('stage-dropdown', 'value'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def update_stage_dropdown(value, n_clicks):\n",
    "    options, stage, backward_table, forward_table, duration_info = generate_data(value)\n",
    "    return options, stage, backward_table, forward_table, duration_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb13a67d-df83-4b55-844f-4348c4eae8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_high_duration_stages():\n",
    "    df = load_cached_data()\n",
    "    df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "    df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "\n",
    "    refined_df = df[df.groupby('application_id')['stage_name'].transform('nunique') > 1]\n",
    "    refined_df = refined_df[refined_df['stage_name'] == 'Hired']\n",
    "    selected_df = df[df['application_id'].isin(refined_df['application_id'])]\n",
    "    df = selected_df\n",
    "\n",
    "    exit_stages = df['stage_name'].unique()\n",
    "    high_duration_stages = {}\n",
    "\n",
    "    for exit_stage in exit_stages:\n",
    "        exit_stage_filter = df['stage_name'] == exit_stage\n",
    "        remaining_duration = df[exit_stage_filter]['exited_on'] - df[exit_stage_filter]['entered_on']\n",
    "        avg_remaining_duration = remaining_duration.mean()\n",
    "        if pd.notna(avg_remaining_duration) and exit_stage != 'Hired':\n",
    "            high_duration_stages[exit_stage] = avg_remaining_duration.days\n",
    "\n",
    "    sorted_high_duration_stages = dict(sorted(high_duration_stages.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_high_duration_stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5852f330-bcc9-4c63-b5d9-56ae44591e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('high-duration-stages', 'children'),\n",
    "    Input('high-duration-stages', 'children')  # Use any input, can be a dummy element\n",
    ")\n",
    "def update_high_duration_stages(dummy_input):\n",
    "    high_duration_stages = calculate_high_duration_stages()\n",
    "    top_10_high_stage_text = [f\"{i+1}. Stage: {stage}, Avg Duration: {duration:.2f} days\" for i, (stage, duration) in enumerate(high_duration_stages.items())][:3]\n",
    "    top_10_high_stage_text = '\\n'.join(top_10_high_stage_text)\n",
    "    return top_10_high_stage_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "277a5bb4-e7b7-4456-a462-492ff602a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('distribution', 'figure'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def distrib_application_per_stage(n_clicks):\n",
    "    df = load_cached_data()\n",
    "    df['month'] = df['applied_at'].dt.month\n",
    "    df['year'] = df['applied_at'].dt.year\n",
    "    df['unique_stages_per_application_candidate'] = df.groupby(['candidate_id', 'application_id'])['stage_name'].transform('nunique')\n",
    "    no_log = df.groupby('year')['unique_stages_per_application_candidate'].value_counts(normalize=True).reset_index(name='normalized_count')\n",
    "    no_log['normalized_count'] = (no_log['normalized_count'] * 100).round(2)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for stage in range(1, 11):\n",
    "        stage_data = no_log[no_log['unique_stages_per_application_candidate'] == stage]\n",
    "        stage_data = stage_data.sort_values('year')\n",
    "        \n",
    "        fig.add_trace(go.Funnel(\n",
    "            name=f'{stage} stage before exit',\n",
    "            y=stage_data['year'].unique(), \n",
    "            x=stage_data['normalized_count'],\n",
    "            textposition='inside',\n",
    "            hoverinfo='text',\n",
    "            opacity=0.75,\n",
    "            marker=dict(line=dict(width=1, color='gray')),\n",
    "            orientation='h',\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Distribution of Applications (%) per Stages in the Process over the Years - Key Clickable',\n",
    "        showlegend=True,\n",
    "        height=500,\n",
    "        width=800,\n",
    "        xaxis=dict(title='Applications that Ended at This Stage'),\n",
    "        yaxis=dict(title='Year', tickmode='array', tickvals=[2018, 2019, 2020]),\n",
    "        hoverlabel=dict(font=dict(size=12)),\n",
    "    )\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64671b26-5066-48b3-a9ee-f5435514a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#duration with radio btn\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "@app.callback(\n",
    "    Output('duration-graph', 'figure'),\n",
    "    Input('duration-graph', 'clickData'),\n",
    "    Input('data-selector', 'value'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def update_duration_graph(click_data, data_selector, n_clicks):\n",
    "    # Update df using load_cached_data() if the button is clicked\n",
    "    if n_clicks is None:\n",
    "        df = load_cached_data()\n",
    "    else:\n",
    "        df = load_cached_data()\n",
    "        df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "        df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "        df['duration'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "    \n",
    "    all_stages_avg_durations = df.groupby('stage_name')['duration'].mean()\n",
    "    \n",
    "    if data_selector == 'selected':\n",
    "        refined_df = df[df.groupby('application_id')['stage_name'].transform('nunique') > 1]\n",
    "        refined_df = refined_df[refined_df['stage_name'] == 'Hired']\n",
    "        selected_df = df[df['application_id'].isin(refined_df['application_id'])]\n",
    "        df = selected_df\n",
    "        selected_stages_avg_durations = df.groupby('stage_name')['duration'].mean()\n",
    "    else:\n",
    "        selected_stages_avg_durations = None\n",
    "    \n",
    "    if click_data and 'points' in click_data:\n",
    "        clicked_stage = click_data['points'][0]['x']\n",
    "        filtered_df = df[df['application_id'].isin(df[df['stage_name'] == clicked_stage]['application_id'])]\n",
    "        avg_durations = filtered_df.groupby('stage_name')['duration'].mean()\n",
    "    else:\n",
    "        avg_durations = all_stages_avg_durations\n",
    "    \n",
    "    fig = px.bar(\n",
    "        avg_durations,\n",
    "        x=avg_durations.index,\n",
    "        y=avg_durations.values,\n",
    "        labels={'x': 'Stage Name', 'y': 'Average Duration (days)'},\n",
    "        title='Average Duration of Stages',\n",
    "    )\n",
    "    \n",
    "    if selected_stages_avg_durations is not None:\n",
    "        scatter_trace = go.Scatter(\n",
    "            x=selected_stages_avg_durations.index,\n",
    "            y=selected_stages_avg_durations.values,\n",
    "            mode='markers',\n",
    "            marker=dict(size=10, color='red')\n",
    "        )\n",
    "        fig.add_trace(scatter_trace)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46008ae3-0f87-47e0-8fc2-be9a6d28c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr matrix\n",
    "def calculate_correlation_matrix(df):\n",
    "    # Filter the DataFrame to include only rows where 'status' is 'hired'\n",
    "    hired_df = df[df['status'] == 'Hired']\n",
    "    \n",
    "    # Convert 'exited_on' and 'entered_on' columns to datetime\n",
    "    hired_df['exited_on'] = pd.to_datetime(hired_df['exited_on'])\n",
    "    hired_df['entered_on'] = pd.to_datetime(hired_df['entered_on'])\n",
    "    \n",
    "    # Calculate length per application stage and length per application\n",
    "    hired_df['length_per_application_stage'] = (hired_df['exited_on'] - hired_df['entered_on']).dt.days\n",
    "    hired_df['length_per_application'] = (hired_df.groupby('application_id')['exited_on'].transform('last') - hired_df.groupby('application_id')['entered_on'].transform('first')).dt.days\n",
    "    \n",
    "    # Select columns of interest\n",
    "    columns_of_interest = ['stage_name', 'length_per_application_stage', 'length_per_application', 'rejection_reason_id', 'job_id', 'source_id', 'referrer_id']\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = hired_df[columns_of_interest].corr(numeric_only=True)\n",
    "    \n",
    "    return correlation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e81bbfb9-25b0-4e81-a95e-712ce06c1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update the correlation heatmap\n",
    "@app.callback(\n",
    "    Output('correlation-heatmap', 'figure'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def update_correlation_heatmap(n_clicks):\n",
    "    #Update df using load_cached_data() if the button is clicked\n",
    "    if n_clicks is None:\n",
    "        df = load_cached_data()\n",
    "    else:\n",
    "        df = load_cached_data()\n",
    "    \n",
    "    correlation_matrix = calculate_correlation_matrix(df)\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.columns,\n",
    "        colorscale='Viridis'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Correlation Heatmap',\n",
    "        xaxis_title='Columns',\n",
    "        yaxis_title='Columns'\n",
    "    )\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dea8eff2-2d82-41d2-abc4-d1b3ed19cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Best Practice Stages\"),\n",
    "                dbc.CardBody([\n",
    "                        # dropdown\n",
    "                        dcc.Dropdown(\n",
    "                            id='stage-dropdown2',\n",
    "                            options=[],\n",
    "                            value=None,\n",
    "                        ),\n",
    "                        dcc.Graph(id='gantt-chart'),\n",
    "                    ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "], fluid=True, style={'padding': '2rem 2rem 8rem 2rem'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b659dc2f-c480-46fc-853f-818bf2cf97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('stage-dropdown2', 'options'),\n",
    "    Output('stage-dropdown2', 'value'),\n",
    "    Output('gantt-chart', 'figure'),\n",
    "    Input('stage-dropdown2', 'value'),\n",
    "    Input('fetch-data-button', 'n_clicks')\n",
    ")\n",
    "def update_gantt_chart(selected_stage, n_clicks):\n",
    "    df = load_cached_data()\n",
    "    # Convert 'entered_on' and 'exited_on' columns to datetime\n",
    "    df['entered_on'] = pd.to_datetime(df['entered_on'])\n",
    "    df['exited_on'] = pd.to_datetime(df['exited_on'])\n",
    "    df['length_per_application_stage'] = (df['exited_on'] - df['entered_on']).dt.days\n",
    "    refined_df = df[df.groupby('application_id')['stage_name'].transform('nunique') > 1]\n",
    "    refined_df = refined_df[refined_df['stage_name'] == 'Hired']\n",
    "    selected_df = df[df['application_id'].isin(refined_df['application_id'])]\n",
    "    stage_names = selected_df['stage_name'].unique()\n",
    "    stage_names = sorted(stage_names.tolist())\n",
    "    options = [{'label': stage, 'value': stage} for stage in stage_names]\n",
    "    if selected_stage is None:\n",
    "        selected_stage = stage_names[0]\n",
    "\n",
    "    stages_min = selected_df[selected_df['stage_name'] == selected_stage].groupby('application_id')[\n",
    "        'length_per_application_stage'].min().idxmin()\n",
    "    \n",
    "    selected_app_df = selected_df[selected_df['application_id'] == stages_min]\n",
    "    \n",
    "    fig = px.timeline(selected_app_df, x_start='entered_on', x_end='exited_on', y='stage_name', color='stage_name')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Gantt Chart of Application {stages_min} Stages',\n",
    "        xaxis_title='Dates',\n",
    "        yaxis_title='Stage',\n",
    "        showlegend=False,\n",
    "        height=400,\n",
    "    )\n",
    "\n",
    "    return options, selected_stage, fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a788e4a3-37f2-4d1e-a7cf-ad8ee0fa666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout\n",
    "predict = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Predictive\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Div([\n",
    "                        # Sliders for variables\n",
    "                        html.Label(\"Adjust variables:\"),\n",
    "                        dcc.Slider(id='slider-variable-1', min=0, max=1, step=0.01, value=0.5, marks={0: '0', 1: '1'}),\n",
    "                        dcc.Dropdown(id='dropdown-variable-2', options=[\n",
    "                            {'label': 'Option 1', 'value': 'option1'},\n",
    "                            {'label': 'Option 2', 'value': 'option2'},\n",
    "                            # Add more options for other categories\n",
    "                        ], value='option1'),\n",
    "                        # Add more sliders/dropdowns for other variables\n",
    "                    ]),\n",
    "                    dcc.Graph(id='hiring-probability')\n",
    "                ])\n",
    "            ], className=\"rounded-0 border-0\")\n",
    "        )\n",
    "    ]),\n",
    "    # dbc.Row([\n",
    "    #     dbc.Col(\n",
    "    #         dbc.Card([\n",
    "    #             dbc.CardHeader(\"Benchmark designing\"),\n",
    "    #             dbc.CardBody([\n",
    "    #                 dcc.Graph(id='stage-gantt')\n",
    "    #             ])\n",
    "    #         ], className=\"rounded-0 border-0\")\n",
    "    #     )\n",
    "    # ]),\n",
    "], fluid=True, style={'padding': '2rem 2rem 8rem 2rem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dea6c9f-1e4a-47c6-88fe-bc04e6ac4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def train_logistic_regression_model(df, columns_of_interest):\n",
    "    # Split the data into features and target\n",
    "    X = df[columns_of_interest]\n",
    "    y = df['status']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95116f2c-a08b-4845-b404-8612d7d0ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('hiring-probability', 'figure'),\n",
    "    Input('slider-variable-1', 'value'),\n",
    "    Input('dropdown-variable-2', 'value'),\n",
    "    # Add more inputs for other sliders/dropdowns\n",
    ")\n",
    "def update_hiring_probability(var1_value, var2_value):\n",
    "    # Load your data\n",
    "    df = load_cached_data()\n",
    "    \n",
    "    # Extract the categorical variable for encoding\n",
    "    categorical_feature = df[['stage_name']]\n",
    "    \n",
    "    # # Initialize the OneHotEncoder\n",
    "    # encoder = OneHotEncoder()\n",
    "    \n",
    "    # # Fit and transform the encoder on the categorical feature\n",
    "    # encoded_stage_name = encoder.fit_transform(categorical_feature)\n",
    "    \n",
    "    # # Retrieve the feature names from the encoder\n",
    "    # encoded_feature_names = encoder.get_feature_names_out(['stage_name'])\n",
    "    \n",
    "    # # Convert the encoded result to a DataFrame\n",
    "    # encoded_stage_name_df = pd.DataFrame(encoded_stage_name.toarray(), columns=encoded_feature_names)\n",
    "    \n",
    "    # # Concatenate the encoded result with your original data\n",
    "    # df_encoded = pd.concat([df, encoded_stage_name_df], axis=1)\n",
    "\n",
    "    # # Get the column names from your DataFrame\n",
    "    # df_columns = df_encoded.columns.tolist()\n",
    "    \n",
    "    # # Define your columns of interest using all columns from df_encoded\n",
    "    # columns_of_interest = df_columns\n",
    "    # #columns_of_interest = ['stage_name_Application Review', 'stage_name_Application Stage', 'stage_name_Face to Face – fly in candidate', 'stage_name_Hired', 'stage_name_Hiring Manager Review', 'stage_name_Interview 1 - F2F', 'stage_name_Interview 1 - F2F - delete', 'stage_name_Interview 1 - Phone/Video', 'stage_name_Interview 2 - F2F', 'stage_name_Interview 2 - Phone/Video', 'stage_name_Interview 3 - F2F', 'stage_name_Interview 3 - Phone/Video', 'stage_name_Offer', 'stage_name_Recruiter Screening', 'stage_name_Recruiter aplication', 'stage_name_Recruiter application', 'stage_name_Recruiter applicaton', 'stage_name_Screened', 'stage_name_Test:SHL', 'stage_name_Test:Take Home']\n",
    "\n",
    "    # #model, X_test, y_test = train_logistic_regression_model(df, columns_of_interest)\n",
    "    # model, X_test, y_test = train_logistic_regression_model(df_encoded, columns_of_interest)\n",
    "\n",
    "    # # Predict the hiring probability for the new data point\n",
    "    # prob_hired = model.predict_proba([[var1_value, var2_value] + [0] * (len(df_columns) - 2)])[:, 1]\n",
    "    \n",
    "    # fig = go.Figure(go.Indicator(\n",
    "    #     mode=\"number+gauge+delta\",\n",
    "    #     value=prob_hired[0],\n",
    "    #     title={'text': \"Predicted Hiring Probability\"},\n",
    "    #     delta={'reference': 0.5, 'position': \"bottom\"},\n",
    "    #     gauge={\n",
    "    #         'axis': {'range': [0, 1]},\n",
    "    #         'bar': {'color': \"darkblue\"},\n",
    "    #         'bgcolor': \"white\",\n",
    "    #         'borderwidth': 2,\n",
    "    #         'bordercolor': \"gray\",\n",
    "    #         'steps': [\n",
    "    #             {'range': [0, 0.3], 'color': \"red\"},\n",
    "    #             {'range': [0.3, 0.7], 'color': \"yellow\"},\n",
    "    #             {'range': [0.7, 1], 'color': \"green\"},\n",
    "    #         ],\n",
    "    #         'threshold': {\n",
    "    #             'line': {'color': \"black\", 'width': 4},\n",
    "    #             'thickness': 0.75,\n",
    "    #             'value': 0.5\n",
    "    #         }\n",
    "    #     }\n",
    "    # ))\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "282a6d5b-688d-459f-9ee4-e4409bfa52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define callback to update the hiring probability\n",
    "# @app.callback(\n",
    "#     Output('hiring-probability', 'children'),\n",
    "#     Input('slider-variable-1', 'value'),\n",
    "#     # Add more inputs for other sliders\n",
    "# )\n",
    "# def update_hiring_probability(var1_value, ...):\n",
    "#     df = load_cached_data()\n",
    "#     columns_of_interest = ['stage_name', 'length_per_application_stage', 'length_per_application', 'rejection_reason_id', 'job_id', 'source_id', 'referrer_id']\n",
    "    \n",
    "#     model, X_test, y_test = train_logistic_regression_model(df, columns_of_interest)\n",
    "#     # Predict the hiring probability for the new data point\n",
    "#     prob_hired = model.predict_proba(new_data)[:, 1]\n",
    "    \n",
    "#     return f\"Predicted Hiring Probability: {prob_hired[0]:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35a5ae-e854-418e-a8ea-e53ffd69d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3cfd2d-694c-482c-a451-832290cabe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#card_link = dbc.CardLink(\"Open Slack\", href=\"https://yourteam.slack.com/channels/<username>\")\n",
    "card  = dbc.Container(\n",
    "    [\n",
    "        dbc.Row(\n",
    "            dbc.Col(html.H4(\"Share Dashboard Outputs\"), width={\"size\": 6, \"offset\": 3}),\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    dbc.CardBody(\n",
    "                        [\n",
    "                            dbc.Row(\n",
    "                                [\n",
    "                                    dbc.Col(html.P(\"Share with a team member\"), width=8),\n",
    "                                    dbc.Col(\n",
    "                                        dbc.Button(\n",
    "                                            \"Share via Slack\",\n",
    "                                            color=\"primary\",\n",
    "                                            id=\"slack-button\",\n",
    "                                            className=\"mr-2\",\n",
    "                                        ),\n",
    "                                        width=2,\n",
    "                                    ),\n",
    "                                    dbc.Col(\n",
    "                                        dbc.Button(\n",
    "                                            \"Share via Email\",\n",
    "                                            color=\"info\",\n",
    "                                            id=\"email-button\",\n",
    "                                        ),\n",
    "                                        width=2,\n",
    "                                    ),\n",
    "                                ],\n",
    "                                align=\"center\",\n",
    "                            ),\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "], fluid=True, style={'padding': '2rem 2rem 8rem 2rem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bc472cd-119a-43cd-a52c-03d8a873aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    dash.dependencies.Output(\"slack-button\", \"href\"),\n",
    "    dash.dependencies.Output(\"email-button\", \"n_clicks\"),\n",
    "    dash.dependencies.Input(\"slack-button\", \"n_clicks\"),\n",
    "    dash.dependencies.Input(\"email-button\", \"n_clicks\"),\n",
    ")\n",
    "def share_outputs_via_slack_and_email(slack_n_clicks, email_n_clicks):\n",
    "    # In this function, you can include the logic to send messages via Slack or email\n",
    "    # Return the appropriate href for Slack and the number of email button clicks\n",
    "    slack_href = \"https://teamname.slack.com/channels/<username>\"\n",
    "    return slack_href, email_n_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "658ab2c2-e580-4e35-b120-eeb5344be150",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "    store, \n",
    "    navbar,\n",
    "    html.Div(id='table-container'),\n",
    "    top_level,\n",
    "    search_container,\n",
    "    page_layout,\n",
    "    process,\n",
    "    predict,\n",
    "    card\n",
    "], style={'padding': '0rem 0rem 4rem 0rem'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73aa8a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8080/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d70c139f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    Timer(1, open_browser).start();\n",
    "    app.run_server(debug=True, use_reloader=False, port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb4afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e67ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc834cb-e84e-46ad-95d5-fb24e89f1c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafb608-99af-406c-862a-832ee4eebeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
